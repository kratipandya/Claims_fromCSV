#!/usr/bin/env python3
"""
Automated claim verification using the OpenRouter API.

Reads a JSON file containing a list of claims (as generated by generate_claims_from_pdf.py),
retrieves supporting context from the source PDF, and asks a verification model
to decide whether each claim is supported ("true") or not ("false").
"""

import argparse
import csv
import json
import os
import re
import time
from difflib import SequenceMatcher
from typing import Iterable, List, Sequence, Tuple

import requests

try:
    from pypdf import PdfReader  # type: ignore
except Exception:  # pragma: no cover - library is optional
    PdfReader = None  # type: ignore


def extract_pdf_text(pdf_path: str, max_pages: int | None = None) -> str:
    """
    Extract text from a PDF using pypdf if available, otherwise try pdfplumber.
    """
    text = ""

    if PdfReader is not None:
        try:
            reader = PdfReader(pdf_path)
            page_iter = (
                range(len(reader.pages))
                if max_pages is None
                else range(min(max_pages, len(reader.pages)))
            )
            for idx in page_iter:
                page = reader.pages[idx]
                page_text = page.extract_text() or ""
                text += "\n" + page_text
        except Exception:
            text = ""

    if not text.strip():
        try:
            import pdfplumber  # type: ignore

            with pdfplumber.open(pdf_path) as pdf:
                pages = (
                    pdf.pages if max_pages is None else pdf.pages[:max_pages]
                )
                for page in pages:
                    page_text = page.extract_text() or ""
                    text += "\n" + page_text
        except Exception:
            pass

    return text.strip()


def clean_text(s: str) -> str:
    """
    Basic cleanup to normalize whitespace and ligatures.
    """
    replacements = {
        '\ufb01': 'fi',
        '\ufb02': 'fl',
        '\u2019': "'",
        '\u2018': "'",
        '\u201c': '\"',
        '\u201d': '\"',
        '\u2014': '-',
        '\u2013': '-',
        '\u2026': '...',
    }
    for bad, good in replacements.items():
        s = s.replace(bad, good)
    s = re.sub(r"\s+", " ", s)
    return s.strip()


def chunk_text(text: str, chunk_chars: int = 2400, overlap: int = 160) -> List[str]:
    """
    Split text into overlapping chunks to supply as context snippets.
    """
    text = text.strip()
    if not text:
        return []

    paragraphs = [p.strip() for p in re.split(r"\n\s*\n", text) if p.strip()]
    chunks: List[str] = []
    current = ""

    for paragraph in paragraphs:
        if len(current) + len(paragraph) + 1 <= chunk_chars:
            current = (current + "\n" + paragraph).strip()
            continue

        if current:
            chunks.append(current)

        if len(paragraph) > chunk_chars:
            step = max(1, chunk_chars - overlap)
            for start in range(0, len(paragraph), step):
                chunks.append(paragraph[start : start + chunk_chars])
            current = ""
        else:
            current = paragraph

    if current:
        chunks.append(current)

    return chunks


STOPWORDS = {
    "a",
    "an",
    "and",
    "are",
    "as",
    "at",
    "be",
    "by",
    "for",
    "from",
    "if",
    "in",
    "is",
    "it",
    "of",
    "on",
    "or",
    "that",
    "the",
    "to",
    "was",
    "were",
    "with",
}


def token_set(text: str) -> set[str]:
    return {t for t in re.findall(r"[A-Za-z]+", text.lower()) if t not in STOPWORDS}


def score_chunk(claim: str, chunk: str) -> float:
    """
    Simple heuristic scoring combining token overlap and sequence similarity.
    """
    claim_tokens = token_set(claim)
    chunk_tokens = token_set(chunk)
    if not claim_tokens or not chunk_tokens:
        overlap = 0.0
    else:
        matches = len(claim_tokens & chunk_tokens)
        overlap = matches / max(1, len(claim_tokens))

    seq_ratio = SequenceMatcher(None, claim.lower(), chunk.lower()).ratio()
    return 0.6 * overlap + 0.4 * seq_ratio


def select_context(claim: str, chunks: Sequence[str], top_k: int = 2) -> str:
    """
    Select the top-k chunks that are most relevant to the claim.
    """
    if not chunks:
        return ""

    scored = sorted(
        ((score_chunk(claim, chunk), chunk) for chunk in chunks),
        key=lambda pair: pair[0],
        reverse=True,
    )
    selected = [chunk for _, chunk in scored[:top_k] if _ > 0]
    if not selected:
        selected = [scored[0][1]]
    return "\n\n".join(selected)


def call_openrouter(
    *,
    api_key: str,
    model: str,
    system_prompt: str,
    user_prompt: str,
    temperature: float,
    max_tokens: int,
    referer: str | None = None,
    title: str | None = None,
    timeout: float = 60.0,
) -> str:
    """
    Send a chat completion request to the OpenRouter API and return the content.
    """
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    if referer:
        headers["HTTP-Referer"] = referer
    if title:
        headers["X-Title"] = title

    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        "temperature": temperature,
        "max_tokens": max_tokens,
    }

    response = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers=headers,
        json=payload,
        timeout=timeout,
    )
    response.raise_for_status()
    data = response.json()
    try:
        return data["choices"][0]["message"]["content"]
    except (KeyError, IndexError) as exc:  # pragma: no cover - only on malformed API responses
        raise RuntimeError(f"Unexpected OpenRouter response: {data}") from exc


def parse_label(text: str) -> str:
    """
    Extract a 'true' or 'false' label from the model response.
    """
    text = text.strip().lower()
    if not text:
        raise ValueError("Empty response from verifier.")

    if text in {"true", "false"}:
        return text

    match = re.search(r"\b(true|false)\b", text)
    if match:
        return match.group(1)

    raise ValueError(f"Could not parse boolean label from response: {text}")


def iter_claims(path: str, limit: int | None = None) -> Iterable[str]:
    """
    Yield claims from a JSON list file. Optionally truncate to 'limit'.
    """
    with open(path, "r", encoding="utf-8") as handle:
        data = json.load(handle)

    if not isinstance(data, list):
        raise ValueError("Claims JSON must be a list of strings.")

    count = 0
    for entry in data:
        if not isinstance(entry, str):
            raise ValueError("Claims JSON contains a non-string entry.")
        yield entry.strip()
        count += 1
        if limit is not None and count >= limit:
            break


def main(argv: Sequence[str] | None = None) -> None:
    parser = argparse.ArgumentParser(
        description="Verify claims against a PDF using an OpenRouter model."
    )
    parser.add_argument(
        "--claims",
        default="claims_evs.json",
        help="Path to JSON file containing a list of claims.",
    )
    parser.add_argument(
        "--pdf",
        default="basics_of_evs.pdf",
        help="Path to the source PDF used to generate the claims.",
    )
    parser.add_argument(
        "--out",
        default="claims_verification.csv",
        help="Destination CSV file for the results.",
    )
    parser.add_argument(
        "--model",
        default="deepseek/deepseek-chat",
        help="OpenRouter model identifier to use for verification.",
    )
    parser.add_argument(
        "--api-key",
        default=None,
        help="OpenRouter API key. If omitted, OPENROUTER_API_KEY env var is used.",
    )
    parser.add_argument(
        "--referer",
        default=None,
        help="Optional HTTP-Referer header value (recommended by OpenRouter).",
    )
    parser.add_argument(
        "--title",
        default="Claim Verification Script",
        help="Optional X-Title header value for OpenRouter.",
    )
    parser.add_argument(
        "--top-k",
        type=int,
        default=2,
        help="Number of context chunks to send alongside each claim.",
    )
    parser.add_argument(
        "--temperature",
        type=float,
        default=0.0,
        help="Sampling temperature for the verifier model.",
    )
    parser.add_argument(
        "--max-tokens",
        type=int,
        default=64,
        help="Max tokens for the verifier completion.",
    )
    parser.add_argument(
        "--sleep",
        type=float,
        default=1.0,
        help="Delay (seconds) between verification requests to avoid rate limits.",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="Verify only the first N claims (for smoke testing).",
    )
    parser.add_argument(
        "--max-pages",
        type=int,
        default=None,
        help="Optional cap on the number of PDF pages to extract for context.",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Print verifier responses for inspection.",
    )
    args = parser.parse_args(argv)

    api_key = args.api_key or os.environ.get("OPENROUTER_API_KEY")
    if not api_key:
        raise SystemExit(
            "Missing API key: provide --api-key or set the OPENROUTER_API_KEY environment variable."
        )

    raw_text = extract_pdf_text(args.pdf, max_pages=args.max_pages)
    if not raw_text.strip():
        raise SystemExit(
            f"Failed to extract any text from {args.pdf}. Install pypdf or pdfplumber and try again."
        )

    cleaned_text = clean_text(raw_text)
    chunks = chunk_text(cleaned_text)
    if not chunks:
        raise SystemExit("No context chunks could be constructed from the PDF.")

    system_prompt = (
        "You are a meticulous fact checker. "
        "When the supplied context clearly supports the claim, respond with 'true'. "
        "If the context contradicts the claim or lacks enough information, respond with 'false'. "
        "Do not speculate. Respond with a single word: 'true' or 'false'."
    )

    claims_iterable = list(iter_claims(args.claims, limit=args.limit))
    results: List[Tuple[str, str]] = []

    for idx, claim in enumerate(claims_iterable, start=1):
        context = select_context(claim, chunks, top_k=args.top_k)
        user_prompt = (
            f"Claim:\n{claim}\n\n"
            "Context:\n"
            f"{context}\n\n"
            "Answer with 'true' if and only if the context proves the claim. "
            "Otherwise answer 'false'."
        )

        try:
            response_text = call_openrouter(
                api_key=api_key,
                model=args.model,
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                temperature=args.temperature,
                max_tokens=args.max_tokens,
                referer=args.referer,
                title=args.title,
            )
            label = parse_label(response_text)
        except Exception as exc:
            label = "false"
            response_text = f"[error] {exc}"

        if args.verbose:
            print(f"[{idx}/{len(claims_iterable)}] {claim}")
            print(f"Label: {label}")
            print(f"Model response: {response_text}")
            print("-" * 40)

        results.append((claim, label))
        time.sleep(max(0.0, args.sleep))

    with open(args.out, "w", newline="", encoding="utf-8") as handle:
        writer = csv.writer(handle)
        writer.writerow(["claim", "label"])
        writer.writerows(results)

    print(f"Wrote {len(results)} rows to {args.out}")


if __name__ == "__main__":  # pragma: no cover
    main()
